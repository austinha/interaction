---
layout: default
---

* TOC
{:toc}

# Context Aware Assignment

**Objective**: Access Android sensors as the preparation to build context aware application.

**Learning Goals**:
- Learn Android Awareness APIs
- Load sensor data
- Understand how and when to use Snapshot or Fence

**Assigned Date**: ???, 2019

**Due Date**: ???, 2019

Tasks:
- Load data from sensor snapshot
- Use Fence to listen to sensor change

After sensing exercise, students will be ready to create a context-aware app.

There are 3 kinds of context:
- Attach context info for later (keep note at a location)
- Automatically execute things (auto correct navigation)
- Present info based on context (show bus info), can be game or util

Each app should use at least two sensors, and one of them should be location.

We provide sample code to use camera. Using camera is not required, but recommended.

It is a group project, each team will send a video. This narrative video will serve as the demonstration for peer grading. (Also submit design wireframe / flow?)

In peer grading survey,
- We will ask what type of context is used
- Ask if the app is enjoyable, in a Likert scale
- Prompt to write a paragraph feedback
- Feedback from users

Critical incident reporting? Heuristic eval?

# Turnin
## Submission Instructions

Please turn in your files in the following zip structure:

```bash
YOUR_STUDENT_ID.zip
├── DrawingView.java
└── MainActivity.java
```

## Grading (10pts)

- Part 1
  - Portrait: 1pt
  - Landscape: 1pt
- Part 2
  - Video: 1pt
- Turn-in and compiles: 1pt
