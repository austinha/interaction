---
layout: default
---

* TOC
{:toc}

# Context Aware Assignment

**Objective**: Access Android sensors as the preparation to build context aware application.

**HCI Goals**:
- Make an enjoyable app
- Use context effectively

**Android Goals**:
- Use location and another sensor
- Understand when to use Snapshot or Fence

**Assigned Date**: ???, 2019

**Due Date**: ???, 2019

Tasks:
- 
- 

After sensing exercise, students will be ready to create a context-aware app.

There are 3 kinds of context:
- Attach context info for later (keep note at a location)
- Automatically execute things (auto correct navigation)
- Present info based on context (show bus info), can be game or util

Each app should use at least two sensors, and one of them should be location.

We provide sample code to use camera. Using camera is not required, but recommended.

It is a group project, each team will send a video. This narrative video will serve as the demonstration for peer grading. (Also submit design wireframe / flow?)

In peer grading survey,
- We will ask what type of context is used
- Ask if the app is enjoyable, in a Likert scale
- Prompt to write a paragraph feedback

Critical incident reporting? Heuristic eval?

# Turnin
## Submission Instructions

Please turn in your files in the following zip structure:

```bash
YOUR_STUDENT_ID.zip
├── DrawingView.java
└── MainActivity.java
```

**HCI Goals**:
- Make an enjoyable app
- Use context effectively

**Android Goals**
- Use location and another sensor
- Understand when to use Snapshot or Fence

## Grading (10pts)

- Part 1: Implementation
  - Use location and another sensor: 1pt
  - App is context-aware: 2pt
- Part 2: Peer grading
  - Submit a narrative video: 2pt
  - Complete peer grading: 1pt
  - Make an enjoyable app: 1pt
  - Peer and you agree with context type: 1pt
- Turn-in and compiles: 1pt
- Group participation: 1pt