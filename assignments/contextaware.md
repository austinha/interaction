---
layout: default
---

* TOC
{:toc}

# Context Aware Assignment

**Objective**: Access Android sensors as the preparation to build context aware application.

**HCI Goals**:
- Make an enjoyable app
- Use context effectively

**Android Goals**:
- Use location and another sensor
- Understand when to use Snapshot or Fence

**Assigned Date**: ???, 2019

**Due Date**: ???, 2019

Task:
- After sensing exercise, students will be ready to create a context-aware app. Please use your creativity :)

There are 3 kinds of context:
- Attach context information for retrieval later (e.g., Leave a note while at CSE; when come back to CSE the day after, user can see the note again)
- Automatically execute things (e.g., Automatically suggest a new navigation route when a driver exits from a wrong ramp.)
- Present info based on context (e.g., Send a notification of bus schedule when user is at bus station)

Students may build an utility app or game, and they should use at least two sensors (**one of them must be location**).

We provide sample code to use camera. Using camera is not required, but recommended.

It is a **group project**. In addition to code, each team will also submit a video. This narrative video will serve as the demonstration for peer grading.

In peer grading survey,
- We will ask what type of context is used
- Ask if the app is enjoyable, in a Likert scale
- Prompt to write a paragraph feedback


# Turnin
## Submission Instructions

Please turn in your files in the following zip structure:

```bash
YOUR_STUDENT_ID.zip
├── src/
└── res/
```

## Grading (10pts)

- Part 1: Implementation
  - Use location and another sensor: 1pt
  - App is context-aware: 2pt
- Part 2: Peer grading
  - Submit a narrative video: 2pt
  - Complete peer grading: 1pt
  - Make an enjoyable app: 1pt
  - Peer and you agree with context type: 1pt
- Turn-in and compiles: 1pt
- Group participation: 1pt