---
layout: assignment
title: Context Awareness
code: A3

assigned: Friday, May 28, 2019
due: 11:59 PM Friday, June 10, 2019
revised: 2:04 PM Wednesday, April 10, 2019

objective: Access Android sensors as the preparation to build context aware application.

android_goals:
  - Use location and another sensor
  - Understand when to use Snapshot or Fence
hci_goals:
  - Make an enjoyable app
  - Use context effectively
---

- TOC
{:toc}

Task:
- After sensing exercise, students will be ready to create a context-aware app. Please use your creativity :)

There are 3 kinds of context:
- Attach context information for retrieval later (e.g., Leave a note while at CSE; when come back to CSE the day after, user can see the note again)
- Automatically execute things (e.g., Automatically suggest a new navigation route when a driver exits from a wrong ramp.)
- Present info based on context (e.g., Send a notification of bus schedule when user is at bus station)

Students may build an utility app or game, and they should use at least two sensors (**one of them must be location**).

We provide sample code to use camera. Using camera is not required, but recommended.

It is a **group project**. In addition to code, each team will also submit a video. This narrative video will serve as the demonstration for peer grading.

In peer grading survey,
- We will ask what type of context is used
- Ask if the app is enjoyable, in a Likert scale
- Prompt to write a paragraph feedback

# Turn-in

## Submission Instructions

You will turn in the following files <a href="javascript:alert('Turn-in link pending assignment release');">here</a>:

```
â”€ src.zip
- res.zip
```

## Grading (10pts)

- Part 1: Implementation
  - Use location and another sensor: 1pt
  - App is context-aware: 2pt
- Part 2: Peer grading
  - Submit a narrative video: 2pt
  - Complete peer grading: 1pt
  - Make an enjoyable app: 1pt
  - Peer and you agree with context type: 1pt
- Code Organization and Style: 1 pt
- Group participation: 1pt
